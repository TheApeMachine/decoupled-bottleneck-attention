version: 1
name: llama32_1b_dba_eval
notes: "Llama 3.2 1B with DBA upcycle + behavioral eval (teacher vs student)."
vars:
  d_model: 2048
  n_heads: 32
  n_kv_heads: 8
  head_dim: 64
  n_layers: 16
  d_ff: 8192
  vocab_size: 128256
defaults:
  tokenizer: llama
  val_frac: 0.05
  instrument: rich
  wandb: true
  wandb_project: "dba-upcycle"
  wandb_entity: ""
  wandb_mode: online
  eval_iters: 50
  save_every: 500
model:
  type: transformer
  embedder:
    type: token
    vocab_size: "${vocab_size}"
    d_model: "${d_model}"
  topology:
    type: stacked
    layers:
      - type: nested
        repeat: "${n_layers}"
        layers:
          - type: residual
            layers:
              - type: rms_norm
                d_model: "${d_model}"
                eps: 1e-5
              - type: attention
                d_model: "${d_model}"
                n_q_heads: "${n_heads}"
                n_kv_heads: "${n_kv_heads}"
                head_dim: "${head_dim}"
                is_causal: true
                dropout_p: 0.0
          - type: residual
            layers:
              - type: rms_norm
                d_model: "${d_model}"
                eps: 1e-5
              - type: swiglu
                d_model: "${d_model}"
                d_ff: "${d_ff}"
                bias: false
      - type: rms_norm
        d_model: "${d_model}"
        eps: 1e-5
      - type: linear
        d_in: "${d_model}"
        d_out: "${vocab_size}"
        bias: false
groups:
  - name: upcycle
    description: "DBA upcycle from Llama 3.2 1B, with behavioral eval."
    data: "fineweb_100m.npy"
    runs:
      - id: blockwise
        mode: train
        exp: dba_blockwise
        seed: 42
        steps: 500
        expected:
          phase: blockwise
        verify:
          type: eval
          tokenizer:
            type: tiktoken
            encoding: llama3
          max_new_tokens: 24
          cases:
            - id: strawberry_r
              prompt: "How many times do we find the letter r in the word strawberry? Answer with a single digit."
              kind: choice_logprob
              choices: ["1", "2", "3", "4"]
              answer: "3"
            - id: arithmetic_17_5
              prompt: "What is 17 + 5? Answer with a single integer."
              kind: choice_logprob
              choices: ["20", "21", "22", "23"]
              answer: "22"
            - id: letters_strawberry
              prompt: "How many letters are in the word strawberry? Answer with a single integer."
              kind: choice_logprob
              choices: ["8", "9", "10", "11"]
              answer: "10"
          thresholds:
            min_student_accuracy: 0.0
            max_accuracy_drop: 1.0
        train:
          phase: blockwise
          batch_size: 1
          block_size: 2048
          lr: 0.0001
          device: mps
          dtype: float32
          teacher_ckpt: "hf://meta-llama/Llama-3.2-1B"
      - id: finetune
        mode: train
        exp: dba_finetune
        seed: 42
        steps: 2000
        expected:
          phase: global
        train:
          phase: global
          batch_size: 1
          block_size: 2048
          lr: 0.00005
          device: mps
          dtype: float32
