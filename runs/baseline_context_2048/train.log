File fineweb_100m.tokens could not be read as space-separated integers. Tokenizing as words...
Tokenized 100002130 tokens. Vocab size: 49761
Device: mps
Tokens: train 90,001,917 | val 10,000,213 | vocab 49,761
Uniform baseline loss log(V): 10.8150 (ppl ~ 49761)
== eval step 0 | train 10.9067 | val 10.9103 | val_ppl 54739.39 | 4.6s
   (new best) 10.9103
step      0/3000 | loss 10.9306 | ppl 55861.45 | tok/s    33862
step     50/3000 | loss 7.5758 | ppl  1950.43 | tok/s    33507
step    100/3000 | loss 6.7695 | ppl   870.83 | tok/s    31822
step    150/3000 | loss 6.4850 | ppl   655.27 | tok/s    31630
step    200/3000 | loss 6.9327 | ppl  1025.22 | tok/s    31503
step    250/3000 | loss 6.5575 | ppl   704.53 | tok/s    30301
step    300/3000 | loss 6.6428 | ppl   767.24 | tok/s    29211
step    350/3000 | loss 6.8137 | ppl   910.19 | tok/s    29310
step    400/3000 | loss 6.3944 | ppl   598.45 | tok/s    29639
step    450/3000 | loss 6.3295 | ppl   560.86 | tok/s    30323
== eval step 500 | train 6.1321 | val 6.0934 | val_ppl 442.91 | 361.5s
   (new best) 6.0934
step    500/3000 | loss 5.9326 | ppl   377.13 | tok/s    30926
step    550/3000 | loss 6.0679 | ppl   431.78 | tok/s    31038
step    600/3000 | loss 5.9098 | ppl   368.65 | tok/s    30834
step    650/3000 | loss 5.8366 | ppl   342.62 | tok/s    31168
step    700/3000 | loss 5.7170 | ppl   304.00 | tok/s    30682
step    750/3000 | loss 5.9015 | ppl   365.59 | tok/s    30118
step    800/3000 | loss 5.9298 | ppl   376.06 | tok/s    29689
step    850/3000 | loss 5.7858 | ppl   325.63 | tok/s    29155
step    900/3000 | loss 5.9816 | ppl   396.09 | tok/s    28446
step    950/3000 | loss 5.3773 | ppl   216.43 | tok/s    28375
== eval step 1000 | train 5.8176 | val 5.6362 | val_ppl 280.39 | 371.1s
   (new best) 5.6362
step   1000/3000 | loss 6.0714 | ppl   433.30 | tok/s    29033
step   1050/3000 | loss 5.7686 | ppl   320.08 | tok/s    27772
step   1100/3000 | loss 5.7107 | ppl   302.08 | tok/s    27113
step   1150/3000 | loss 5.6858 | ppl   294.65 | tok/s    27903
step   1200/3000 | loss 5.6353 | ppl   280.15 | tok/s    27938
step   1250/3000 | loss 5.6192 | ppl   275.68 | tok/s    28249
step   1300/3000 | loss 5.4051 | ppl   222.53 | tok/s    27399
step   1350/3000 | loss 5.6736 | ppl   291.09 | tok/s    27821
step   1400/3000 | loss 5.6833 | ppl   293.92 | tok/s    28579
step   1450/3000 | loss 5.4726 | ppl   238.08 | tok/s    28381
== eval step 1500 | train 5.4367 | val 5.3606 | val_ppl 212.84 | 395.4s
   (new best) 5.3606
step   1500/3000 | loss 5.5303 | ppl   252.22 | tok/s    28473
step   1550/3000 | loss 5.4364 | ppl   229.62 | tok/s    28230
step   1600/3000 | loss 5.2259 | ppl   186.03 | tok/s    27766
step   1650/3000 | loss 5.6815 | ppl   293.40 | tok/s    27233
step   1700/3000 | loss 5.2217 | ppl   185.26 | tok/s    27906
step   1750/3000 | loss 5.6260 | ppl   277.54 | tok/s    30926
step   1800/3000 | loss 5.1761 | ppl   176.99 | tok/s    30873
step   1850/3000 | loss 5.3314 | ppl   206.73 | tok/s    30683
step   1900/3000 | loss 5.4076 | ppl   223.09 | tok/s    29996
step   1950/3000 | loss 5.0496 | ppl   155.96 | tok/s    29798
== eval step 2000 | train 5.2462 | val 5.1317 | val_ppl 169.31 | 379.5s
   (new best) 5.1317
step   2000/3000 | loss 5.2820 | ppl   196.75 | tok/s    29530
step   2050/3000 | loss 5.0409 | ppl   154.61 | tok/s    29992
step   2100/3000 | loss 5.2639 | ppl   193.23 | tok/s    29370
step   2150/3000 | loss 5.2785 | ppl   196.08 | tok/s    27292
step   2200/3000 | loss 5.0806 | ppl   160.88 | tok/s    29720
step   2250/3000 | loss 5.0398 | ppl   154.43 | tok/s    28605
step   2300/3000 | loss 5.1139 | ppl   166.31 | tok/s    29959
step   2350/3000 | loss 4.9733 | ppl   144.50 | tok/s    30169
step   2400/3000 | loss 5.4596 | ppl   235.01 | tok/s    30467
step   2450/3000 | loss 5.1289 | ppl   168.83 | tok/s    30422
== eval step 2500 | train 4.9918 | val 4.9760 | val_ppl 144.90 | 375.7s
   (new best) 4.9760
step   2500/3000 | loss 5.3354 | ppl   207.55 | tok/s    30440
step   2550/3000 | loss 5.0644 | ppl   158.29 | tok/s    29848
step   2600/3000 | loss 5.0566 | ppl   157.06 | tok/s    29155
step   2650/3000 | loss 5.0787 | ppl   160.56 | tok/s    28704
step   2700/3000 | loss 5.0282 | ppl   152.65 | tok/s    30285
step   2750/3000 | loss 4.8715 | ppl   130.52 | tok/s    30872
step   2800/3000 | loss 4.9958 | ppl   147.80 | tok/s    30609
step   2850/3000 | loss 4.9185 | ppl   136.80 | tok/s    30373
step   2900/3000 | loss 4.8413 | ppl   126.64 | tok/s    30863
step   2950/3000 | loss 4.8315 | ppl   125.40 | tok/s    30486
== eval step 3000 | train 4.9376 | val 4.8689 | val_ppl 130.18 | 370.4s
   (new best) 4.8689
Done. best_val=4.8689